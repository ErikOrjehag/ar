<!doctype html>
<!--
Copyright 2018 The Immersive Web Community Group

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
    <meta name='mobile-web-app-capable' content='yes'>
    <meta name='apple-mobile-web-app-capable' content='yes'>
    <link rel='icon' type='image/png' sizes='32x32' href='favicon-32x32.png'>
    <link rel='icon' type='image/png' sizes='96x96' href='favicon-96x96.png'>
    <link rel='stylesheet' href='css/common.css'>

    <title>Pfizer AR</title>
  </head>
  <body>
    <header>
      <div class="details" open>
        <summary>Pfizer Oncology AR Greeting</summary>
        <p>
          Welcome to this Augmented Reality (AR) experience. Make sure to stand in a well lit room with some free floor space. Press the button below to start the AR experience. Press “allow” when permission to use the camera is requested.
          <br/><br/>
          <img src="/phone.png" style="width: 100%;" />
          <br/><br/>
          You will then see your camera view on your  phone. Move your phone around in sweeping motions until you can see a blue circle appear on the floor. Place the blue circle approximately 2 meters away from you and then tap your screen to start the AR Greeting.
          <br />
        </p>
      </div>
      <div style="text-align: right;">
        <br />
        <img src="/pfizer-logo.png" style="width: 30%;" />
      </div>
    </header>
    <script type="module">
      import {WebXRButton} from './js/util/webxr-button.js';
      import {Scene} from './js/render/scenes/scene.js';
      import {Renderer, createWebGLContext} from './js/render/core/renderer.js';
      import {Node} from './js/render/core/node.js';
      import {Gltf2Node} from './js/render/nodes/gltf2.js';
      import {VideoNodeMasked} from './js/render/nodes/video-masked.js?asd=123';
      import {DropShadowNode} from './js/render/nodes/drop-shadow.js';
      import {vec3, mat4} from './js/render/math/gl-matrix.js';
      import {Ray} from './js/render/math/ray.js';

      // XR globals.
      let xrButton = null;
      let xrRefSpace = null;
      let xrViewerSpace = null;
      let xrHitTestSource = null;

      // WebGL scene globals.
      let gl = null;
      let renderer = null;
      let scene = new Scene();
      scene.enableStats(false);

      let arObject = new Node();
      arObject.visible = false;
      scene.addNode(arObject);

      //let flower = new Gltf2Node({url: 'media/gltf/sunflower/sunflower.gltf'});
      //arObject.addNode(flower);

      let video = document.createElement('video');
      //video.loop = true;
      video.disablePictureInPicture = true;
      video.playsInline = true;
      video.src = 'media/video/pfizer.mp4';

      const videoScale = 1.21;

      let videoNode = new VideoNodeMasked({video: video});
      videoNode.scale = [videoScale, videoScale, 1.0];
      arObject.addNode(videoNode);

      video.addEventListener('loadeddata', () => {
        // Once the video has loaded up adjust the aspect ratio of the "screen"
        // to fit the video's native shape.
        let width = video.videoWidth;
        let height = video.videoHeight;
        let aspect = (width / 2.0) / height;

        console.log("LOADED VIDEO!", width, height, aspect);

        videoNode.scale[0] *= aspect;
      });

      let reticle = new Gltf2Node({url: 'media/gltf/reticle/reticle.gltf'});
      reticle.visible = false;
      scene.addNode(reticle);

      // Having a really simple drop shadow underneath an object helps ground
      // it in the world without adding much complexity.
      /*let shadow = new DropShadowNode();
      vec3.set(shadow.scale, 0.15, 0.15, 0.15);
      vec3.set(shadow.translation, 0.0, 0.0, 1.0);
      arObject.addNode(shadow);*/

      const MAX_FLOWERS = 1;
      let flowers = [];

      // Ensure the background is transparent for AR.
      scene.clear = false;

      function initXR() {
        xrButton = new WebXRButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession,
          textEnterXRTitle: "START AR",
          textXRNotFoundTitle: "AR NOT FOUND",
          textExitXRTitle: "EXIT AR",
        });
        document.querySelector('.details').appendChild(xrButton.domElement);

        if (navigator.xr) {
          navigator.xr.isSessionSupported('immersive-ar')
                      .then((supported) => {
            xrButton.enabled = supported;
          });
        }
      }

      function onRequestSession() {
        return navigator.xr.requestSession('immersive-ar', {requiredFeatures: ['local', 'hit-test']})
                           .then((session) => {
          xrButton.setSession(session);
          onSessionStarted(session);
        });
      }

      function onSessionStarted(session) {
        session.addEventListener('end', onSessionEnded);
        session.addEventListener('select', onSelect);

        if (!gl) {
          gl = createWebGLContext({
            xrCompatible: true
          });
          const width = window.innerWidth && document.documentElement.clientWidth ? 
            Math.min(window.innerWidth, document.documentElement.clientWidth) : 
            window.innerWidth || document.documentElement.clientWidth || document.getElementsByTagName('body')[0].clientWidth;
          const height = window.innerHeight && document.documentElement.clientHeight ? 
            Math.min(window.innerHeight, document.documentElement.clientHeight) : 
            window.innerHeight || document.documentElement.clientHeight || document.getElementsByTagName('body')[0].clientHeight;
          
          gl.canvas.width = width;
          gl.canvas.height = height;

          renderer = new Renderer(gl);

          scene.setRenderer(renderer);
        }

        session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

        // In this sample we want to cast a ray straight out from the viewer's
        // position and render a reticle where it intersects with a real world
        // surface. To do this we first get the viewer space, then create a
        // hitTestSource that tracks it.
        session.requestReferenceSpace('viewer').then((refSpace) => {
          xrViewerSpace = refSpace;
          session.requestHitTestSource({ space: xrViewerSpace }).then((hitTestSource) => {
            xrHitTestSource = hitTestSource;
          });
        });

        session.requestReferenceSpace('local').then((refSpace) => {
          xrRefSpace = refSpace;

          session.requestAnimationFrame(onXRFrame);
        });
      }

      function onEndSession(session) {
        xrHitTestSource.cancel();
        xrHitTestSource = null;
        session.end();
      }

      function onSessionEnded(event) {
        xrButton.setSession(null);
      }

      // Adds a new object to the scene at the
      // specified transform.
      function addARObjectAt(matrix) {

        let newMatrix = mat4.create();
        mat4.translate(newMatrix, matrix, vec3.fromValues(0.0, videoScale*0.8, 0.0));

        console.log(matrix, newMatrix);

        let newFlower = arObject.clone();
        newFlower.visible = true;
        newFlower.matrix = newMatrix;
        scene.addNode(newFlower);

        flowers.push(newFlower);

        video.play();

        // For performance reasons if we add too many objects start
        // removing the oldest ones to keep the scene complexity
        // from growing too much.
        if (flowers.length > MAX_FLOWERS) {
          let oldFlower = flowers.shift();
          scene.removeNode(oldFlower);
        }
      }

      let rayOrigin = vec3.create();
      let rayDirection = vec3.create();
      function onSelect(event) {
        if (reticle.visible) {
          // The reticle should already be positioned at the latest hit point, 
          // so we can just use it's matrix to save an unnecessary call to 
          // event.frame.getHitTestResults.
          addARObjectAt(reticle.matrix);
        }
      }

      // Called every time a XRSession requests that a new frame be drawn.
      function onXRFrame(t, frame) {
        let session = frame.session;
        let pose = frame.getViewerPose(xrRefSpace);

        reticle.visible = false;

        // If we have a hit test source, get its results for the frame
        // and use the pose to display a reticle in the scene.
        if (xrHitTestSource && pose) {
          let hitTestResults = frame.getHitTestResults(xrHitTestSource);
          if (hitTestResults.length > 0) {
            let pose = hitTestResults[0].getPose(xrRefSpace);
            reticle.visible = true;
            reticle.matrix = pose.transform.matrix;
          }
        }

        scene.startFrame();

        session.requestAnimationFrame(onXRFrame);

        scene.drawXRFrame(frame, pose);

        scene.endFrame();
      }

      // Start the XR application.
      initXR();
    </script>
  </body>
</html>
